{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## notebook to load the model from drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Path to the zip file in Google Drive\n",
    "zip_path = '/content/drive/My Drive/llm_models/fine-tuned-t5.zip'\n",
    "\n",
    "# Path to the directory where you want to extract the files\n",
    "extract_path = '/content/sample_data/model'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "!mkdir -p \"{extract_path}\"\n",
    "\n",
    "# Unzip the file\n",
    "!unzip \"{zip_path}\" -d \"{extract_path}\"\n",
    "\n",
    "print(f'Files extracted to {extract_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "model_path = '/content/sample_data/model'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
    "\n",
    "# Create a pipeline for text generation\n",
    "text2text_generator = pipeline('text2text-generation', model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Define the prompt\n",
    "desc_cap = [\"dog\", \"beach\", \"sun\"]\n",
    "emotion = \"happy\"\n",
    "userpref = \"fiction\"\n",
    "\n",
    "prompt = (\n",
    "    f\"Generate a story that evokes a {emotion} emotion. The story should feature a \"\n",
    "    f\"{keywords[0]}, a {keywords[1]}, and a {keywords[2]}. \"\n",
    "    f\"Additionally, incorporate elements of {userpref} to enhance the narrative. \"\n",
    "    f\"Ensure the {userpref} aspects are seamlessly integrated and contribute to the overall {emotion} tone of the story.\"\n",
    ")\n",
    "\n",
    "# Generate the story\n",
    "generated_story = text2text_generator(prompt, max_length=512, do_sample=True, top_p=0.95, num_return_sequences=1)\n",
    "\n",
    "# Print the generated story\n",
    "print(generated_story[0]['generated_text'])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
