{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9_FhQkgKxIN"
      },
      "source": [
        "# Fine Tuning With Flan T5 XL\n",
        "\n",
        "Author : Sivaprasad Puthumadathil Rameshan Nair\n",
        "\n",
        "Flan-T5 XL Model\n",
        "\n",
        "- 3 Billion Parameters\n",
        "- Model Type: Language model\n",
        "- Architecture: Flan-T5 XL is based on the T5 (Text-To-Text Transfer Transformer) architecture developed by Google, which uses a transformer-based approach that is highly effective for various natural language processing (NLP) tasks.\n",
        "- Performance: The model excels in a wide range of tasks, including translation, summarization, question answering, and text generation.\n",
        "Instruction Fine-Tuning: Flan-T5 XL has been fine-tuned with instruction-based data, showing significant improvements in benchmarks over models that were not fine-tuned in this manner.\n",
        "- Human-Like Text Generation: It has demonstrated exceptional performance in tasks that require both understanding and generating human-like text, making it highly suitable for applications that require nuanced and coherent language generation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3U7sw2CK2xg"
      },
      "source": [
        "## 1. Story generation before fine tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "929cd860966648938068f2160d3f72c0",
            "a08db49d8cb24d3e9310489f31e1f6b8",
            "2633ad03604f4d60866dbf87051df4d1",
            "51b5979f5a2b4e8fa54919a0e5ae4612",
            "74127e2a462d452e90a25c732625bb90",
            "c051106b580b4256b3742af4c1ea1d91",
            "8047ae216fcb48d99c63bd881a1be0d2",
            "8357a3028e8c4eb0bf01c80c0bfc5af5",
            "943fe98675df4fb88eada309c84412d4",
            "67874516341b4dbd81f47e05d186f155",
            "1a2de30bba69483ba999511f2820ce46"
          ]
        },
        "id": "2KSuc8k7JUyW",
        "outputId": "b68f5dd8-75b2-44b5-c542-adf9bbded69f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "929cd860966648938068f2160d3f72c0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken to generate the story: 1.86 seconds\n",
            "The dog was happy to be on the beach. He was laying in the sun and enjoying the warm weather. The sun was shining brightly and the dog loved the warmth.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# Check if a GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load the tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-xl\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-xl\").to(device)  # Ensure the model is on the same device\n",
        "\n",
        "# Function to generate text\n",
        "def generate_story_with_keywords(keywords, emotion, userpref, max_length=150):\n",
        "    # Create the prompt for the story generation\n",
        "    prompt = (\n",
        "        f\"Generate a story that evokes a {emotion} emotion. The story should feature a \"\n",
        "        f\"{keywords[0]}, a {keywords[1]}, and a {keywords[2]}. \"\n",
        "        f\"Additionally, incorporate elements of {userpref} to enhance the narrative. \"\n",
        "        f\"Ensure the {userpref} aspects are seamlessly integrated and contribute to the overall {emotion} tone of the story.\"\n",
        "    )\n",
        "\n",
        "    # Encode the prompt\n",
        "    inputs = tokenizer.encode(prompt, return_tensors='pt').to(device)  # Ensure the inputs are on the same device\n",
        "\n",
        "    # Generate the story\n",
        "    start_time = time.time()\n",
        "    outputs = model.generate(\n",
        "        inputs,\n",
        "        max_length=max_length,\n",
        "        num_return_sequences=1,\n",
        "        no_repeat_ngram_size=2,\n",
        "        early_stopping=True,\n",
        "        temperature=0.7,  # Control the randomness of predictions\n",
        "        top_k=50  # Limit the sampling pool to top_k tokens\n",
        "    )\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Decode the generated text\n",
        "    story = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    print(f\"Time taken to generate the story: {end_time - start_time:.2f} seconds\")\n",
        "    return story\n",
        "\n",
        "# Define the keywords, emotion, and user preferences\n",
        "keywords = [\"dog\", \"sun\", \"beach\"]\n",
        "emotion = \"happy\"\n",
        "userpref = \"history\"\n",
        "\n",
        "# Generate the story\n",
        "story = generate_story_with_keywords(keywords, emotion, userpref, max_length=512)\n",
        "\n",
        "# Function to save the story to a file\n",
        "def save_story_to_file(story, filename='/content/sample_data/generated_story_flan-t5-xl.txt'):\n",
        "    with open(filename, 'w') as file:\n",
        "        file.write(story)\n",
        "\n",
        "# Save the generated story to a file\n",
        "save_story_to_file(story)\n",
        "\n",
        "# Print the generated story\n",
        "print(story)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "my7SqALXK79Q"
      },
      "source": [
        "## 2. Dataset Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4fP4y1fLCOh",
        "outputId": "c91ed211-4ce8-4227-95ac-7c429979e764"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file while skipping problematic lines\n",
        "processed_data = pd.read_csv('/content/sample_data/stories_with_features_with_genre.csv', on_bad_lines='warn')\n",
        "processed_data.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "_3X1qp-oMlWX",
        "outputId": "0a661d10-4b62-4bc5-9c3b-1ac082ed9376"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       id                                              story  \\\n",
              "0  457580  In the year 2250, Earth had made significant s...   \n",
              "1  297904  In a land far away, where the sun shone bright...   \n",
              "2  620436  Once upon a time, in a small, tranquil town ca...   \n",
              "3  634687  Once upon a time in the 16th century, a small ...   \n",
              "4  513427  In the sun-drenched coastal city of St. August...   \n",
              "\n",
              "                  genre                                         characters  \\\n",
              "0       Science Fiction  scientist, star, Shadowbeast, Reynolds, UEG, e...   \n",
              "1               Fantasy  the Shadow Beast's, Thorn, Eldoria, sorcerer, ...   \n",
              "2               Mystery  detective, Thomas, Johnathan, Whispering Shado...   \n",
              "3  Historical Adventure  William, Elias, the Emerald Amulet, Blackwood,...   \n",
              "4              Thriller  Alex, Florida, Katie, Sarah, Thomas, artist, P...   \n",
              "\n",
              "                        objects  \\\n",
              "0                    ship, game   \n",
              "1  Sword, puzzle, scroll, sword   \n",
              "2                           NaN   \n",
              "3                           key   \n",
              "4           computer, map, game   \n",
              "\n",
              "                                           locations vehicles professions  \\\n",
              "0           spacecraft, fortress, field, moon Europa      NaN    inventor   \n",
              "1  the Sword of Eldoria, The Sword of Eldoria, br...      NaN  adventurer   \n",
              "2              valley, town, warehouse, city, square      NaN         NaN   \n",
              "3                       temple, town, trail, village      NaN         NaN   \n",
              "4                       bar, city, ocean, Laboratory      NaN      lawyer   \n",
              "\n",
              "                                            emotions  \n",
              "0                          despair, hope, excitement  \n",
              "1                          determination, excitement  \n",
              "2  shock, love, hope, determination, gratitude, g...  \n",
              "3                     hope, determination, gratitude  \n",
              "4                       despair, hope, determination  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ff7b348a-8cd3-4b74-b9fb-fe1b23dc10f9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>story</th>\n",
              "      <th>genre</th>\n",
              "      <th>characters</th>\n",
              "      <th>objects</th>\n",
              "      <th>locations</th>\n",
              "      <th>vehicles</th>\n",
              "      <th>professions</th>\n",
              "      <th>emotions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>457580</td>\n",
              "      <td>In the year 2250, Earth had made significant s...</td>\n",
              "      <td>Science Fiction</td>\n",
              "      <td>scientist, star, Shadowbeast, Reynolds, UEG, e...</td>\n",
              "      <td>ship, game</td>\n",
              "      <td>spacecraft, fortress, field, moon Europa</td>\n",
              "      <td>NaN</td>\n",
              "      <td>inventor</td>\n",
              "      <td>despair, hope, excitement</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>297904</td>\n",
              "      <td>In a land far away, where the sun shone bright...</td>\n",
              "      <td>Fantasy</td>\n",
              "      <td>the Shadow Beast's, Thorn, Eldoria, sorcerer, ...</td>\n",
              "      <td>Sword, puzzle, scroll, sword</td>\n",
              "      <td>the Sword of Eldoria, The Sword of Eldoria, br...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>adventurer</td>\n",
              "      <td>determination, excitement</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>620436</td>\n",
              "      <td>Once upon a time, in a small, tranquil town ca...</td>\n",
              "      <td>Mystery</td>\n",
              "      <td>detective, Thomas, Johnathan, Whispering Shado...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>valley, town, warehouse, city, square</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>shock, love, hope, determination, gratitude, g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>634687</td>\n",
              "      <td>Once upon a time in the 16th century, a small ...</td>\n",
              "      <td>Historical Adventure</td>\n",
              "      <td>William, Elias, the Emerald Amulet, Blackwood,...</td>\n",
              "      <td>key</td>\n",
              "      <td>temple, town, trail, village</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>hope, determination, gratitude</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>513427</td>\n",
              "      <td>In the sun-drenched coastal city of St. August...</td>\n",
              "      <td>Thriller</td>\n",
              "      <td>Alex, Florida, Katie, Sarah, Thomas, artist, P...</td>\n",
              "      <td>computer, map, game</td>\n",
              "      <td>bar, city, ocean, Laboratory</td>\n",
              "      <td>NaN</td>\n",
              "      <td>lawyer</td>\n",
              "      <td>despair, hope, determination</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff7b348a-8cd3-4b74-b9fb-fe1b23dc10f9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ff7b348a-8cd3-4b74-b9fb-fe1b23dc10f9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ff7b348a-8cd3-4b74-b9fb-fe1b23dc10f9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9060fa3b-5dbf-4637-bff8-e980452f715a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9060fa3b-5dbf-4637-bff8-e980452f715a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9060fa3b-5dbf-4637-bff8-e980452f715a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "processed_data",
              "summary": "{\n  \"name\": \"processed_data\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 290220,\n        \"min\": 1328,\n        \"max\": 998783,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          189780,\n          623454,\n          853098\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"story\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"Elara was a young and vivacious girl living in the small, serene town of Willow Creek. Life was a simple melody in her world; her days were filled with laughter, play, and the gentle rustling of leaves from the trees that lined the streets. Her parents, Maris and Lillian, were the kindest and most loving souls she had ever known, and her best friend, Amelia, was the perfect companion.\\n\\nElara's life took a magical turn when her twelfth birthday arrived. As she blew out the candles on her cake, she whispered a secret wish: \\\"To uncover the hidden mysteries of Willow Creek and bring joy to all who live here.\\\"\\n\\nSuddenly, a shimmering light filled the room, and a beautiful, ethereal being appeared before her. This enchanting being was none other than the spirit of the town, Willow. She revealed to Elara that the town was home to an ancient, magical force that had been dormant for centuries. Elara was chosen to awaken this force and use it to bring happiness and prosperity to Willow Creek.\\n\\nEmboldened by her newfound purpose, Elara embarked on a journey through the enchanted woods surrounding Willow Creek. Each step she took, the magical energy around her grew stronger, and the flora and fauna seemed to dance and sing in harmony.\\n\\nElara soon discovered that the magical force was in the form of a mystical tree, the Heartwood Tree. Its roots were intertwined with the very essence of the town, and its branches touched the sky, reaching out to the heavens. Elara knew that if she could unlock the Heartwood Tree's power, she would be able to fulfill her destiny.\\n\\nAs she approached the tree, she encountered a series of challenges and obstacles, each more difficult than the last. Elara's courage and resilience were tested as she faced the villainous creatures and dark forces that stood between her and the Heartwood Tree.\\n\\nFirst, she encountered the Whispering Winds, a malicious entity that sought to manipulate Elara's thoughts and cause her to lose her way. With a steady heart and unwavering determination, she battled the Whispering Winds and emerged victorious.\\n\\nNext, she faced the Dark Shadow, a monstrous entity that sought to consume all light and happiness in Willow Creek. Elara used her newfound magical abilities to harness the power of the sun and banish the Dark Shadow, restoring the town's radiant beauty.\\n\\nFinally, Elara confronted the enigmatic figure of the Shadow Master, a being that had been orchestrating the dark forces in the town for centuries. In a fierce battle of wills and magic, Elara managed to defeat the Shadow Master and sever the connection between the dark forces and the Heartwood Tree.\\n\\nWith the Heartwood Tree's power now free from the influence of darkness, Elara began to unlock the tree's magical secrets. The Heartwood Tree granted her the ability to communicate with the animals, plants, and even the very elements of nature.\\n\\nElara used her newfound powers to bring about a golden age of prosperity and happiness in Willow Creek. The town's residents thrived under her guidance, and the magical energy of the Heartwood Tree infused every aspect of their lives.\\n\\nHowever, as the years passed, Elara's powers began to wane, and the magical energy of the Heartwood Tree started to fade. The people of Willow Creek, now reliant on the magic that had once brought them joy, began to fear the loss of their magical world.\\n\\nAs Elara's powers faded, so too did her health. She knew that she could not bear the burden of the Heartwood Tree's power forever, and it was time for her to pass on her responsibility to someone else.\\n\\nElara embarked on one final journey through the enchanted woods, seeking a suitable successor who could continue her legacy. Along the way, she discovered Amelia, her childhood friend, who had been transformed into a magical being by the Heartwood Tree's energy.\\n\\nRealizing that Amelia had the strength and compassion to fulfill her destiny, Elara passed on the Heartwood Tree's powers to her. With newfound magical abilities, Amelia vowed to continue Elara's mission and bring happiness and prosperity to Willow Creek for generations to come.\\n\\nAs the sun set on the final chapter of Elara's story, she knew that her journey had come full circle. The enchanted woods of Willow Creek would continue to thrive under Amelia's watchful eye, and the magical legacy of the Heartwood Tree would live on for centuries to come.\\n\\nThe End\",\n          \"Emily Williams, born in the quaint little town of Willowbrook in 1902, was an ordinary girl with extraordinary dreams. From a young age, she displayed an uncanny interest in the world around her and a fierce determination to make a difference.\\n\\nHer childhood was a typical one, filled with the laughter and tears of her loving family. Her father, a hardworking man, was a devoted breadwinner, while her mother, a gentle soul, was a nurturing presence. Emily had two younger siblings, both of whom she adored and protected.\\n\\nEmily's early years were marked by her insatiable curiosity and her unwavering desire to learn. She would spend hours upon hours, nose buried in books, devouring every piece of information she could find. Her parents, recognizing her potential, encouraged her to pursue her passions and supported her every step of the way.\\n\\nAs she grew older, Emily's interest turned towards social justice, and she became increasingly aware of the world's inequalities. She was a bright and ambitious young woman, determined to make her mark on the world.\\n\\nAt the age of 17, Emily moved to the bustling city of New York to attend Columbia University, where she studied sociology and political science. It was here that she developed a strong network of friends and mentors who helped shape her into the person she was destined to become.\\n\\nEmily's time in college was marked by her involvement in various social and political movements of the era. She was an active participant in the women's suffrage movement, and she worked tirelessly to promote the rights of African Americans and laborers.\\n\\nIn 1924, Emily graduated from Columbia University with honors, her academic achievements earning her a prestigious scholarship to further her studies in England. It was during her time in England that she became deeply involved in the burgeoning labor movement, advocating for workers' rights and better working conditions.\\n\\nIn 1926, Emily returned to the United States, where she continued her work as an activist and social reformer. She became a prominent figure in the labor movement, working closely with trade unions and labor organizations to improve the lives of workers across the country.\\n\\nDuring the Great Depression, Emily was a tireless advocate for the unemployed and the poor, using her platform to raise awareness and demand government action. Her efforts earned her the admiration and respect of her peers, as well as the enmity of powerful business interests, who saw her as a threat to their profit margins.\\n\\nAs World War II loomed, Emily's focus shifted towards international affairs. She became an outspoken critic of fascism and an ardent supporter of the Allied cause. Her dedication to the war effort led her to join the Office of Strategic Services (OSS), the precursor to the Central Intelligence Agency (CIA), where she used her intelligence and skills to gather information and support the resistance movements in Europe.\\n\\nEmily's work with the OSS took her to the war-torn continent, where she faced danger and adversity at every turn. Despite the risks, she remained unwavering in her commitment to the cause, using her wit and guile to outmaneuver her enemies and aid the Allied forces in their fight against tyranny.\\n\\nIn 1944, Emily was involved in a daring operation to rescue a group of Allied soldiers trapped behind enemy lines. The mission was a success, but it came at a high cost, as Emily was gravely injured in the process. Her injuries left her with a permanent limp, a constant reminder of the sacrifices she had made in the pursuit of her ideals.\\n\\nAfter the war, Emily continued her work as an advocate for social justice, focusing her efforts on the fight against poverty and the promotion of human rights. She worked closely with the United Nations and various non-governmental organizations to promote peace and understanding across the globe.\\n\\nIn 1952, Emily was awarded the Presidential Medal of Freedom, the highest civilian honor in the United States, in recognition of her lifetime of service to her country and her unwavering commitment to the ideals of freedom and equality.\\n\\nAs she approached her twilight years, Emily continued to be a force for good, inspiring generations of activists and reformers to follow in her footsteps. Her legacy was one of courage, perseverance, and unyielding dedication to the cause of social justice.\\n\\nHowever, Emily's story took a dark turn in her final years. Plagued by loneliness and the weight of her past, she became increasingly reclusive, seeking solace in the memories of her youth. It was during this time that she began to receive anonymous threats, warning her of the consequences of her actions.\\n\\nIn 1973, Emily was found dead in her home, the victim of an apparent suicide. The circumstances surrounding her death were shrouded in mystery, and many questioned the official conclusion. Was it the result of a broken heart, or was there a more sinister force at play?\\n\\nEmily Williams' life was a tapestry of heroism, sacrifice, and tragedy, a testament to the indomitable spirit of a woman who dedicated her life to the pursuit of justice. Her story serves as a reminder that the threads of destiny are often interwoven with strands of darkness and light, and that the choices we make can shape the course of our lives and the world around us.\",\n          \"In the year 1590, a new era dawned upon the kingdom of Eldoria, a realm of unparalleled beauty and prosperity. The kingdom was ruled by the benevolent King Alaric, known for his wisdom and fairness. However, the times were fraught with danger, as dark forces lurked in the shadows, plotting to bring chaos and destruction to Eldoria.\\n\\nAmidst these tumultuous times, a hero emerged, a man of courage and integrity, who would become synonymous with the very essence of valor. This was none other than Sir Reginald, a seasoned knight of the realm, who had dedicated his life to the service of the kingdom. With his sharp intellect, unparalleled martial skills, and unwavering loyalty, Sir Reginald had earned the trust and admiration of King Alaric and the people of Eldoria.\\n\\nIn the heart of the kingdom, a young orphan named Aelwyn lived a humble life, working as an apprentice to the village blacksmith. Aelwyn was a bright and resourceful youth, who had a natural affinity for forging and crafting metal. Despite her modest beginnings, Aelwyn harbored dreams of becoming a legendary blacksmith, one who would forge weapons for the greatest heroes of the realm.\\n\\nOne fateful day, as fate would have it, Aelwyn's life would intertwine with that of Sir Reginald, and together, they would embark on an epic adventure that would forever change the course of Eldorian history.\\n\\nAs the years passed, the kingdom of Eldoria faced a series of trials and tribulations, as the forces of darkness began to gather strength and challenge the kingdom's very existence. The sinister cult of the Iron Phoenix, a fanatical group of warriors and sorcerers, sought to bring about the fall of Eldoria and establish a tyrannical rule over the land.\\n\\nThe cult's leader, the enigmatic and ruthless Lord Blackthorn, was an immensely powerful sorcerer, who had amassed a vast army of loyal followers, ready to do his bidding and bring about his twisted vision of the world. As the cult's influence grew, so too did the sense of dread and despair that hung over the kingdom like a dark cloud.\\n\\nIn response to the growing threat, King Alaric called upon his most trusted knights, including the legendary Sir Reginald, to form a secret council known as the Order of the Phoenix. The council's mission was to uncover the secrets of the Iron Phoenix and put an end to their nefarious schemes before the kingdom fell into darkness.\\n\\nAs the Order of the Phoenix assembled, Sir Reginald found himself in need of a skilled blacksmith to forge the weapons that would be vital to the success of their mission. In his search for the perfect craftsman, he stumbled upon Aelwyn, who had recently completed her apprenticeship and was eager to make her mark on the world.\\n\\nUpon seeing Aelwyn's extraordinary talent and dedication, Sir Reginald took her under his wing and introduced her to the secrets of forging weapons of legendary power. Together, they began to create a series of weapons, each more powerful than the last, which would be wielded by the members of the Order of the Phoenix in their battle against the Iron Phoenix.\\n\\nAs the Order of the Phoenix embarked on their perilous journey, they faced countless trials and battles, as they delved deeper into the heart of darkness that lay at the center of the Iron Phoenix's power. Along the way, they uncovered ancient secrets and forged alliances with other brave souls who shared their determination to protect the kingdom.\\n\\nAs the members of the Order of the Phoenix grew closer, they began to realize that they were not just fighting against the Iron Phoenix, but against the very darkness that lay within their own hearts. The struggle to maintain their integrity and loyalty in the face of such overwhelming evil would prove to be their greatest challenge, as they were forced to confront the true nature of their own souls.\\n\\nThroughout their journey, Aelwyn and Sir Reginald forged a bond that transcended friendship and became something truly special. As they worked together to create the weapons that would determine the fate of Eldoria, they discovered that their destinies were intertwined, and that their success would be dependent on their unwavering trust in one another.\\n\\nAs the Order of the Phoenix continued their quest, they discovered that the source of the Iron Phoenix's power lay within the heart of a dormant volcano, which had long been considered a sacred place by the people of Eldoria. It was here that the cult had built their stronghold, and it was here that the members of the Order would have to face their most fearsome enemies in a final battle for the soul of Eldoria.\\n\\nAs the climactic battle unfolded, Aelwyn and Sir Reginald found themselves confronted by the full might of the Iron Phoenix's forces, led by the cunning and ruthless Lord Blackthorn. In a desperate bid to save their kingdom, the members of the Order of the Phoenix fought with every ounce of strength and skill they possessed, as the very fate of Eldoria hung in the balance.\\n\\nAs the battle raged on, Aelwyn and Sir Reginald faced off against Lord Blackthorn in a duel that would determine the outcome of the entire conflict. In a breathtaking display of skill and courage, Aelwyn managed to craft a powerful weapon that would strike at the very heart of Lord Blackthorn's dark power, and with a final, desperate swing, she struck the decisive blow that would seal his fate.\\n\\nWith the defeat of Lord Blackthorn, the Iron Phoenix's power began to crumble, and the members of the Order of the Phoenix were able to put an end to the cult's reign of terror. As the kingdom celebrated their victory, Aelwyn and Sir Reginald were hailed as heroes, their names forever etched in the annals of Eldorian history.\\n\\nIn the aftermath of their great adventure, Aelwyn and Sir Reginald returned to their homeland, where they continued to work together, forging weapons and protecting the kingdom from the various threats that still lingered in the shadows. As they forged their weapons, they also forged a bond that would stand the test of time, a bond that would endure long after their days as heroes had passed.\\n\\nAnd so, the tale of Aelwyn and Sir Reginald, the Iron Phoenix's greatest adversaries, would become a legend that would be passed down through the generations, a testament to the power of friendship, loyalty, and the indomitable spirit of heroes who would always stand ready to defend their kingdom, no matter the cost.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"genre\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 99,\n        \"samples\": [\n          \"Alternate Dimension\",\n          \"Disaster\",\n          \"Steampunk Fantasy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"characters\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 999,\n        \"samples\": [\n          \"star, Lieutenant, Cat, O'Reilly, Alistair Blackthorn, Centauri 3,, the Black Star, Reynolds, The Black Star, UPC, The Outlaw's Gambit\\n\\n    In, the Black Star's, James \\\"Jim\\\" O'Reilly, Earth, The Black Star's, Blackthorn, United Planets Coalition, Star, the Star's End, Captain, Centauri 3\",\n          \"the Magical Guardian, Saphira, Together, the Council of Magical Guardians, the Magical Guardians, the Enchanted Crystals, Magical Guardian, Enchanted Crystal, The Enchanted Crystals, Aura, sorcerer, Malvoreth, Starshine Academy, hero, Saphira the Magical\",\n          \"the Crimson Fox, the Crimson Caper, Lucy, Cat, Detective Turner, Crimson Caper, detective, The Crimson Caper, Lucy Johnson, Detective, Turner, New York, thief, Jack Turner, moon, The Crimson Fox, ghost, red crescent, Johnson, The Unsolved Mystery\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"objects\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 301,\n        \"samples\": [\n          \"tool, bed\",\n          \"ring, lamp, game\",\n          \"painting, cup, bread\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"locations\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 816,\n        \"samples\": [\n          \"the Hundred-Handed Ones, grove, path\",\n          \"field, stadium, park, apartment, path, city\",\n          \"fortress, path, hill\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vehicles\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"caravan\",\n          \"wagon\",\n          \"ferry\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"professions\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 71,\n        \"samples\": [\n          \"baker\",\n          \"inventor\",\n          \"adventurer, scholar\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"emotions\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 421,\n        \"samples\": [\n          \"despair, hope, curiosity, love\",\n          \"pride, fear, hope, determination, gratitude, relief\",\n          \"hope, determination, fearlessness, excitement\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "processed_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7GVjNqmMpAD",
        "outputId": "fb1599ef-98c6-4afc-dd5d-3a8c3c97bdf2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'story', 'genre', 'characters', 'objects', 'locations',\n",
              "       'vehicles', 'professions', 'emotions'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "processed_data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5q_ZFBXqMqaq",
        "outputId": "b0481edb-87b5-46bf-d987-80380b228583"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id               0\n",
              "story            0\n",
              "genre            0\n",
              "characters       1\n",
              "objects        344\n",
              "locations       47\n",
              "vehicles       976\n",
              "professions    728\n",
              "emotions       133\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "processed_data.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJgbMYGoMsMv",
        "outputId": "c012e359-d053-4e2e-d704-0373313d8e8e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'story', 'genre', 'characters', 'objects', 'locations',\n",
              "       'professions', 'emotions'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df = processed_data.drop(columns=['vehicles'])\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snK-OWMVMwH7",
        "outputId": "2a7fd62b-0a53-40bb-963b-d67b08170300"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id             0\n",
              "story          0\n",
              "genre          0\n",
              "characters     0\n",
              "objects        0\n",
              "locations      0\n",
              "professions    0\n",
              "emotions       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Handle NaN values: Fill NaN values with a default string\n",
        "df.fillna('Unknown', inplace=True)\n",
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "dPkWaOfFQv8l",
        "outputId": "70db2868-6066-4892-9b1b-70b9774caa0b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       id                                              story  \\\n",
              "0  457580  In the year 2250, Earth had made significant s...   \n",
              "1  297904  In a land far away, where the sun shone bright...   \n",
              "2  620436  Once upon a time, in a small, tranquil town ca...   \n",
              "3  634687  Once upon a time in the 16th century, a small ...   \n",
              "4  513427  In the sun-drenched coastal city of St. August...   \n",
              "\n",
              "                  genre                                         characters  \\\n",
              "0       Science Fiction  scientist, star, Shadowbeast, Reynolds, UEG, e...   \n",
              "1               Fantasy  the Shadow Beast's, Thorn, Eldoria, sorcerer, ...   \n",
              "2               Mystery  detective, Thomas, Johnathan, Whispering Shado...   \n",
              "3  Historical Adventure  William, Elias, the Emerald Amulet, Blackwood,...   \n",
              "4              Thriller  Alex, Florida, Katie, Sarah, Thomas, artist, P...   \n",
              "\n",
              "                        objects  \\\n",
              "0                    ship, game   \n",
              "1  Sword, puzzle, scroll, sword   \n",
              "2                       Unknown   \n",
              "3                           key   \n",
              "4           computer, map, game   \n",
              "\n",
              "                                           locations professions  \\\n",
              "0           spacecraft, fortress, field, moon Europa    inventor   \n",
              "1  the Sword of Eldoria, The Sword of Eldoria, br...  adventurer   \n",
              "2              valley, town, warehouse, city, square     Unknown   \n",
              "3                       temple, town, trail, village     Unknown   \n",
              "4                       bar, city, ocean, Laboratory      lawyer   \n",
              "\n",
              "                                            emotions  \n",
              "0                          despair, hope, excitement  \n",
              "1                          determination, excitement  \n",
              "2  shock, love, hope, determination, gratitude, g...  \n",
              "3                     hope, determination, gratitude  \n",
              "4                       despair, hope, determination  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3c34120f-2198-4baf-a81b-f79d37ca2b7d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>story</th>\n",
              "      <th>genre</th>\n",
              "      <th>characters</th>\n",
              "      <th>objects</th>\n",
              "      <th>locations</th>\n",
              "      <th>professions</th>\n",
              "      <th>emotions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>457580</td>\n",
              "      <td>In the year 2250, Earth had made significant s...</td>\n",
              "      <td>Science Fiction</td>\n",
              "      <td>scientist, star, Shadowbeast, Reynolds, UEG, e...</td>\n",
              "      <td>ship, game</td>\n",
              "      <td>spacecraft, fortress, field, moon Europa</td>\n",
              "      <td>inventor</td>\n",
              "      <td>despair, hope, excitement</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>297904</td>\n",
              "      <td>In a land far away, where the sun shone bright...</td>\n",
              "      <td>Fantasy</td>\n",
              "      <td>the Shadow Beast's, Thorn, Eldoria, sorcerer, ...</td>\n",
              "      <td>Sword, puzzle, scroll, sword</td>\n",
              "      <td>the Sword of Eldoria, The Sword of Eldoria, br...</td>\n",
              "      <td>adventurer</td>\n",
              "      <td>determination, excitement</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>620436</td>\n",
              "      <td>Once upon a time, in a small, tranquil town ca...</td>\n",
              "      <td>Mystery</td>\n",
              "      <td>detective, Thomas, Johnathan, Whispering Shado...</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>valley, town, warehouse, city, square</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>shock, love, hope, determination, gratitude, g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>634687</td>\n",
              "      <td>Once upon a time in the 16th century, a small ...</td>\n",
              "      <td>Historical Adventure</td>\n",
              "      <td>William, Elias, the Emerald Amulet, Blackwood,...</td>\n",
              "      <td>key</td>\n",
              "      <td>temple, town, trail, village</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>hope, determination, gratitude</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>513427</td>\n",
              "      <td>In the sun-drenched coastal city of St. August...</td>\n",
              "      <td>Thriller</td>\n",
              "      <td>Alex, Florida, Katie, Sarah, Thomas, artist, P...</td>\n",
              "      <td>computer, map, game</td>\n",
              "      <td>bar, city, ocean, Laboratory</td>\n",
              "      <td>lawyer</td>\n",
              "      <td>despair, hope, determination</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c34120f-2198-4baf-a81b-f79d37ca2b7d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3c34120f-2198-4baf-a81b-f79d37ca2b7d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3c34120f-2198-4baf-a81b-f79d37ca2b7d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5227e271-1ffc-4e89-ac25-ba77f5135f85\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5227e271-1ffc-4e89-ac25-ba77f5135f85')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5227e271-1ffc-4e89-ac25-ba77f5135f85 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 290220,\n        \"min\": 1328,\n        \"max\": 998783,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          189780,\n          623454,\n          853098\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"story\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"Elara was a young and vivacious girl living in the small, serene town of Willow Creek. Life was a simple melody in her world; her days were filled with laughter, play, and the gentle rustling of leaves from the trees that lined the streets. Her parents, Maris and Lillian, were the kindest and most loving souls she had ever known, and her best friend, Amelia, was the perfect companion.\\n\\nElara's life took a magical turn when her twelfth birthday arrived. As she blew out the candles on her cake, she whispered a secret wish: \\\"To uncover the hidden mysteries of Willow Creek and bring joy to all who live here.\\\"\\n\\nSuddenly, a shimmering light filled the room, and a beautiful, ethereal being appeared before her. This enchanting being was none other than the spirit of the town, Willow. She revealed to Elara that the town was home to an ancient, magical force that had been dormant for centuries. Elara was chosen to awaken this force and use it to bring happiness and prosperity to Willow Creek.\\n\\nEmboldened by her newfound purpose, Elara embarked on a journey through the enchanted woods surrounding Willow Creek. Each step she took, the magical energy around her grew stronger, and the flora and fauna seemed to dance and sing in harmony.\\n\\nElara soon discovered that the magical force was in the form of a mystical tree, the Heartwood Tree. Its roots were intertwined with the very essence of the town, and its branches touched the sky, reaching out to the heavens. Elara knew that if she could unlock the Heartwood Tree's power, she would be able to fulfill her destiny.\\n\\nAs she approached the tree, she encountered a series of challenges and obstacles, each more difficult than the last. Elara's courage and resilience were tested as she faced the villainous creatures and dark forces that stood between her and the Heartwood Tree.\\n\\nFirst, she encountered the Whispering Winds, a malicious entity that sought to manipulate Elara's thoughts and cause her to lose her way. With a steady heart and unwavering determination, she battled the Whispering Winds and emerged victorious.\\n\\nNext, she faced the Dark Shadow, a monstrous entity that sought to consume all light and happiness in Willow Creek. Elara used her newfound magical abilities to harness the power of the sun and banish the Dark Shadow, restoring the town's radiant beauty.\\n\\nFinally, Elara confronted the enigmatic figure of the Shadow Master, a being that had been orchestrating the dark forces in the town for centuries. In a fierce battle of wills and magic, Elara managed to defeat the Shadow Master and sever the connection between the dark forces and the Heartwood Tree.\\n\\nWith the Heartwood Tree's power now free from the influence of darkness, Elara began to unlock the tree's magical secrets. The Heartwood Tree granted her the ability to communicate with the animals, plants, and even the very elements of nature.\\n\\nElara used her newfound powers to bring about a golden age of prosperity and happiness in Willow Creek. The town's residents thrived under her guidance, and the magical energy of the Heartwood Tree infused every aspect of their lives.\\n\\nHowever, as the years passed, Elara's powers began to wane, and the magical energy of the Heartwood Tree started to fade. The people of Willow Creek, now reliant on the magic that had once brought them joy, began to fear the loss of their magical world.\\n\\nAs Elara's powers faded, so too did her health. She knew that she could not bear the burden of the Heartwood Tree's power forever, and it was time for her to pass on her responsibility to someone else.\\n\\nElara embarked on one final journey through the enchanted woods, seeking a suitable successor who could continue her legacy. Along the way, she discovered Amelia, her childhood friend, who had been transformed into a magical being by the Heartwood Tree's energy.\\n\\nRealizing that Amelia had the strength and compassion to fulfill her destiny, Elara passed on the Heartwood Tree's powers to her. With newfound magical abilities, Amelia vowed to continue Elara's mission and bring happiness and prosperity to Willow Creek for generations to come.\\n\\nAs the sun set on the final chapter of Elara's story, she knew that her journey had come full circle. The enchanted woods of Willow Creek would continue to thrive under Amelia's watchful eye, and the magical legacy of the Heartwood Tree would live on for centuries to come.\\n\\nThe End\",\n          \"Emily Williams, born in the quaint little town of Willowbrook in 1902, was an ordinary girl with extraordinary dreams. From a young age, she displayed an uncanny interest in the world around her and a fierce determination to make a difference.\\n\\nHer childhood was a typical one, filled with the laughter and tears of her loving family. Her father, a hardworking man, was a devoted breadwinner, while her mother, a gentle soul, was a nurturing presence. Emily had two younger siblings, both of whom she adored and protected.\\n\\nEmily's early years were marked by her insatiable curiosity and her unwavering desire to learn. She would spend hours upon hours, nose buried in books, devouring every piece of information she could find. Her parents, recognizing her potential, encouraged her to pursue her passions and supported her every step of the way.\\n\\nAs she grew older, Emily's interest turned towards social justice, and she became increasingly aware of the world's inequalities. She was a bright and ambitious young woman, determined to make her mark on the world.\\n\\nAt the age of 17, Emily moved to the bustling city of New York to attend Columbia University, where she studied sociology and political science. It was here that she developed a strong network of friends and mentors who helped shape her into the person she was destined to become.\\n\\nEmily's time in college was marked by her involvement in various social and political movements of the era. She was an active participant in the women's suffrage movement, and she worked tirelessly to promote the rights of African Americans and laborers.\\n\\nIn 1924, Emily graduated from Columbia University with honors, her academic achievements earning her a prestigious scholarship to further her studies in England. It was during her time in England that she became deeply involved in the burgeoning labor movement, advocating for workers' rights and better working conditions.\\n\\nIn 1926, Emily returned to the United States, where she continued her work as an activist and social reformer. She became a prominent figure in the labor movement, working closely with trade unions and labor organizations to improve the lives of workers across the country.\\n\\nDuring the Great Depression, Emily was a tireless advocate for the unemployed and the poor, using her platform to raise awareness and demand government action. Her efforts earned her the admiration and respect of her peers, as well as the enmity of powerful business interests, who saw her as a threat to their profit margins.\\n\\nAs World War II loomed, Emily's focus shifted towards international affairs. She became an outspoken critic of fascism and an ardent supporter of the Allied cause. Her dedication to the war effort led her to join the Office of Strategic Services (OSS), the precursor to the Central Intelligence Agency (CIA), where she used her intelligence and skills to gather information and support the resistance movements in Europe.\\n\\nEmily's work with the OSS took her to the war-torn continent, where she faced danger and adversity at every turn. Despite the risks, she remained unwavering in her commitment to the cause, using her wit and guile to outmaneuver her enemies and aid the Allied forces in their fight against tyranny.\\n\\nIn 1944, Emily was involved in a daring operation to rescue a group of Allied soldiers trapped behind enemy lines. The mission was a success, but it came at a high cost, as Emily was gravely injured in the process. Her injuries left her with a permanent limp, a constant reminder of the sacrifices she had made in the pursuit of her ideals.\\n\\nAfter the war, Emily continued her work as an advocate for social justice, focusing her efforts on the fight against poverty and the promotion of human rights. She worked closely with the United Nations and various non-governmental organizations to promote peace and understanding across the globe.\\n\\nIn 1952, Emily was awarded the Presidential Medal of Freedom, the highest civilian honor in the United States, in recognition of her lifetime of service to her country and her unwavering commitment to the ideals of freedom and equality.\\n\\nAs she approached her twilight years, Emily continued to be a force for good, inspiring generations of activists and reformers to follow in her footsteps. Her legacy was one of courage, perseverance, and unyielding dedication to the cause of social justice.\\n\\nHowever, Emily's story took a dark turn in her final years. Plagued by loneliness and the weight of her past, she became increasingly reclusive, seeking solace in the memories of her youth. It was during this time that she began to receive anonymous threats, warning her of the consequences of her actions.\\n\\nIn 1973, Emily was found dead in her home, the victim of an apparent suicide. The circumstances surrounding her death were shrouded in mystery, and many questioned the official conclusion. Was it the result of a broken heart, or was there a more sinister force at play?\\n\\nEmily Williams' life was a tapestry of heroism, sacrifice, and tragedy, a testament to the indomitable spirit of a woman who dedicated her life to the pursuit of justice. Her story serves as a reminder that the threads of destiny are often interwoven with strands of darkness and light, and that the choices we make can shape the course of our lives and the world around us.\",\n          \"In the year 1590, a new era dawned upon the kingdom of Eldoria, a realm of unparalleled beauty and prosperity. The kingdom was ruled by the benevolent King Alaric, known for his wisdom and fairness. However, the times were fraught with danger, as dark forces lurked in the shadows, plotting to bring chaos and destruction to Eldoria.\\n\\nAmidst these tumultuous times, a hero emerged, a man of courage and integrity, who would become synonymous with the very essence of valor. This was none other than Sir Reginald, a seasoned knight of the realm, who had dedicated his life to the service of the kingdom. With his sharp intellect, unparalleled martial skills, and unwavering loyalty, Sir Reginald had earned the trust and admiration of King Alaric and the people of Eldoria.\\n\\nIn the heart of the kingdom, a young orphan named Aelwyn lived a humble life, working as an apprentice to the village blacksmith. Aelwyn was a bright and resourceful youth, who had a natural affinity for forging and crafting metal. Despite her modest beginnings, Aelwyn harbored dreams of becoming a legendary blacksmith, one who would forge weapons for the greatest heroes of the realm.\\n\\nOne fateful day, as fate would have it, Aelwyn's life would intertwine with that of Sir Reginald, and together, they would embark on an epic adventure that would forever change the course of Eldorian history.\\n\\nAs the years passed, the kingdom of Eldoria faced a series of trials and tribulations, as the forces of darkness began to gather strength and challenge the kingdom's very existence. The sinister cult of the Iron Phoenix, a fanatical group of warriors and sorcerers, sought to bring about the fall of Eldoria and establish a tyrannical rule over the land.\\n\\nThe cult's leader, the enigmatic and ruthless Lord Blackthorn, was an immensely powerful sorcerer, who had amassed a vast army of loyal followers, ready to do his bidding and bring about his twisted vision of the world. As the cult's influence grew, so too did the sense of dread and despair that hung over the kingdom like a dark cloud.\\n\\nIn response to the growing threat, King Alaric called upon his most trusted knights, including the legendary Sir Reginald, to form a secret council known as the Order of the Phoenix. The council's mission was to uncover the secrets of the Iron Phoenix and put an end to their nefarious schemes before the kingdom fell into darkness.\\n\\nAs the Order of the Phoenix assembled, Sir Reginald found himself in need of a skilled blacksmith to forge the weapons that would be vital to the success of their mission. In his search for the perfect craftsman, he stumbled upon Aelwyn, who had recently completed her apprenticeship and was eager to make her mark on the world.\\n\\nUpon seeing Aelwyn's extraordinary talent and dedication, Sir Reginald took her under his wing and introduced her to the secrets of forging weapons of legendary power. Together, they began to create a series of weapons, each more powerful than the last, which would be wielded by the members of the Order of the Phoenix in their battle against the Iron Phoenix.\\n\\nAs the Order of the Phoenix embarked on their perilous journey, they faced countless trials and battles, as they delved deeper into the heart of darkness that lay at the center of the Iron Phoenix's power. Along the way, they uncovered ancient secrets and forged alliances with other brave souls who shared their determination to protect the kingdom.\\n\\nAs the members of the Order of the Phoenix grew closer, they began to realize that they were not just fighting against the Iron Phoenix, but against the very darkness that lay within their own hearts. The struggle to maintain their integrity and loyalty in the face of such overwhelming evil would prove to be their greatest challenge, as they were forced to confront the true nature of their own souls.\\n\\nThroughout their journey, Aelwyn and Sir Reginald forged a bond that transcended friendship and became something truly special. As they worked together to create the weapons that would determine the fate of Eldoria, they discovered that their destinies were intertwined, and that their success would be dependent on their unwavering trust in one another.\\n\\nAs the Order of the Phoenix continued their quest, they discovered that the source of the Iron Phoenix's power lay within the heart of a dormant volcano, which had long been considered a sacred place by the people of Eldoria. It was here that the cult had built their stronghold, and it was here that the members of the Order would have to face their most fearsome enemies in a final battle for the soul of Eldoria.\\n\\nAs the climactic battle unfolded, Aelwyn and Sir Reginald found themselves confronted by the full might of the Iron Phoenix's forces, led by the cunning and ruthless Lord Blackthorn. In a desperate bid to save their kingdom, the members of the Order of the Phoenix fought with every ounce of strength and skill they possessed, as the very fate of Eldoria hung in the balance.\\n\\nAs the battle raged on, Aelwyn and Sir Reginald faced off against Lord Blackthorn in a duel that would determine the outcome of the entire conflict. In a breathtaking display of skill and courage, Aelwyn managed to craft a powerful weapon that would strike at the very heart of Lord Blackthorn's dark power, and with a final, desperate swing, she struck the decisive blow that would seal his fate.\\n\\nWith the defeat of Lord Blackthorn, the Iron Phoenix's power began to crumble, and the members of the Order of the Phoenix were able to put an end to the cult's reign of terror. As the kingdom celebrated their victory, Aelwyn and Sir Reginald were hailed as heroes, their names forever etched in the annals of Eldorian history.\\n\\nIn the aftermath of their great adventure, Aelwyn and Sir Reginald returned to their homeland, where they continued to work together, forging weapons and protecting the kingdom from the various threats that still lingered in the shadows. As they forged their weapons, they also forged a bond that would stand the test of time, a bond that would endure long after their days as heroes had passed.\\n\\nAnd so, the tale of Aelwyn and Sir Reginald, the Iron Phoenix's greatest adversaries, would become a legend that would be passed down through the generations, a testament to the power of friendship, loyalty, and the indomitable spirit of heroes who would always stand ready to defend their kingdom, no matter the cost.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"genre\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 99,\n        \"samples\": [\n          \"Alternate Dimension\",\n          \"Disaster\",\n          \"Steampunk Fantasy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"characters\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"Lillian, Elara, Willow, the Heartwood Tree, Willow Creek, the Heartwood Tree's, Amelia, Maris, sun, tree\",\n          \"Allied, CIA, the United States, the Presidential Medal of Freedom, New York, England, Emily Williams', the Office of Strategic Services, Willowbrook, Emily Williams, Europe, OSS, Columbia University, the United Nations, African Americans, the Central Intelligence Agency, Emily\",\n          \"Aelwyn, Blackthorn, Eldorian, blacksmith, King Alaric, Order, Reginald, the Order of the Phoenix, Eldoria, King, sorcerer, knight, Phoenix, hero\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"objects\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 302,\n        \"samples\": [\n          \"key, cloak\",\n          \"knife, camera\",\n          \"door, key\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"locations\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 817,\n        \"samples\": [\n          \"forest, Forest, village\",\n          \"Crescent Bay, Bay, town, Ocean, path, store\",\n          \"mansion, city, prison, house\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"professions\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 72,\n        \"samples\": [\n          \"inventor, explorer\",\n          \"lawyer, judge, Judge\",\n          \"lawyer, judge\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"emotions\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 422,\n        \"samples\": [\n          \"happiness, relief, love, hope\",\n          \"Hope, hope, determination, relief, anger\",\n          \"happiness, hope, love\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a49VmmI5MzL3"
      },
      "source": [
        "## 3. Loading the data for fine tuning\n",
        "\n",
        "let's concatenates various columns from the dataset into a single text string. This string is intended to be used as input for fine-tuning the model. The idea is to create a rich and informative prompt that includes multiple aspects of the story, such as characters, objects, locations, professions, and emotions.\n",
        "\n",
        "How It Works:\n",
        "\n",
        "- data['story']: Contains the main story text.\n",
        "- data['characters']: Contains characters mentioned in the story.\n",
        "- data['objects']: Contains objects referenced in the story.\n",
        "- data['locations']: Contains locations where the story takes place.\n",
        "- data['professions']: Contains professions of characters in the story.\n",
        "- data['emotions']: Contains emotions depicted in the story."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "6lK8bXqqtdbX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "outputId": "08090359-e601-4128-9fa8-4cc71755def1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/547.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.2/547.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Collecting requests>=2.32.2 (from datasets)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, requests, pyarrow, dill, multiprocess, datasets\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.20.0 dill-0.3.8 multiprocess-0.70.16 pyarrow-17.0.0 requests-2.32.3 xxhash-3.4.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pyarrow"
                ]
              },
              "id": "5f4b7141d2bc432c8fe696dd52e53062"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1cw-a6qkMzwD"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Concatenate input features into a single input string, without the vehicle column\n",
        "df['input_text'] = df.apply(lambda row: f\"Genre: {row['genre']} Characters: {row['characters']} Objects: {row['objects']} Locations: {row['locations']} Professions: {row['professions']} Emotions: {row['emotions']}\", axis=1)\n",
        "df['target_text'] = df['story']\n",
        "\n",
        "# Convert the DataFrame to a Hugging Face dataset\n",
        "dataset = Dataset.from_pandas(df[['input_text', 'target_text']])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jWIHnajOb-d"
      },
      "source": [
        "## 4. Tokenising the data\n",
        "\n",
        "Tokenize the text data to prepare it for model training.\n",
        "\n",
        "Tokenizing the data is a crucial step in preparing text for model training, especially for transformer models like T5\n",
        "\n",
        "Why Tokenize the Data?\n",
        "\n",
        "- Converting Text to Numerical Format: Machine learning models, particularly neural networks, require numerical input. Tokenization converts text into a sequence of numbers (token IDs) that the model can process.\n",
        "- Handling Vocabulary: Tokenization breaks down text into smaller units (tokens), such as words or subwords, and maps each token to a unique ID in the model's vocabulary. This helps the model understand and generate text.\n",
        "- Managing Input Length: Tokenization ensures that text inputs are appropriately truncated or padded to a fixed length. This uniformity is essential for batch processing in model training.\n",
        "- Preserving Meaning: Advanced tokenizers (like the one used for T5) often use subword units, which helps in handling out-of-vocabulary words and preserving the semantic meaning of the text.\n",
        "\n",
        "What Does Tokenization Involve?\n",
        "\n",
        "- Splitting Text into Tokens: The text is split into smaller units (tokens), which can be words, subwords, or characters.\n",
        "- Mapping Tokens to IDs: Each token is mapped to a unique ID in the model’s vocabulary.\n",
        "- Truncating or Padding Sequences: The tokenized sequences are truncated to a maximum length if they are too long, or padded with special tokens if they are too short. This ensures all sequences in a batch have the same length."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190,
          "referenced_widgets": [
            "4d081a51209344b9a7f3ebe4ffca9d0b",
            "d7c72edf420c49f0b3375ca4fb3fe44e",
            "1f07205c1329480387f7c3bd61ff1d2e",
            "336c52413ef144248e5d9514396da7ef",
            "e188e9b534774129a37ae9b2c7dab2aa",
            "74066a827a5c459fab44d60f533c7074",
            "da3bc0325df84defbc0526ab7c1b47ea",
            "5bcb0f9fc3c5406fbccb28ee2522e4d1",
            "00c3de6ec2844b37be660b32eac0dfb5",
            "309664e894be4bcf8fa75381b657d369",
            "d29beda83e86417cb71d94ab71845565"
          ]
        },
        "id": "WB41ejidOZRt",
        "outputId": "a6695b8d-a43d-4d51-8eb7-2629a5ab8c2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:99: UserWarning: \n",
            "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
            "You are not authenticated with the Hugging Face Hub in this notebook.\n",
            "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d081a51209344b9a7f3ebe4ffca9d0b"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('google/flan-t5-xl')\n",
        "\n",
        "# Tokenize the dataset with padding\n",
        "def tokenize_function(examples):\n",
        "    model_inputs = tokenizer(examples['input_text'], max_length=512, padding=\"max_length\", truncation=True)\n",
        "    labels = tokenizer(examples['target_text'], max_length=512, padding=\"max_length\", truncation=True)\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKZkWbvYNXdd",
        "outputId": "d702106c-1a8a-4210-ae28-88154c9905c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1:\n",
            "Tokenized Input IDs: [5945, 60, 10, 2854, 24525, 20087, 7, 10, 17901, 6, 2213, 6, 18136, 115, 11535, 6, 27815, 6, 412, 8579, 6, 9739, 6, 30059, 6, 10498, 6, 11856, 6, 8, 638, 7, 3113, 391, 99, 17, 19746, 2661, 7038, 6, 12202, 27815, 6, 13622, 6, 24308, 6, 19553, 6, 3, 4256, 6, 8114, 6, 4030, 6, 30486, 6, 1079, 96, 683, 4365, 121, 27815, 6, 17687, 6, 13962, 6, 736, 13240, 10498, 6, 37, 907, 4030, 3141, 6, 11566, 120, 29, 96, 427, 162, 1686, 12202, 6, 205, 13223, 6, 160, 32, 3, 17057, 7, 10, 4383, 6, 467, 10450, 7, 10, 628, 6696, 6, 21, 9746, 6, 1057, 6, 8114, 5578, 749, 17585, 7, 10, 21244, 262, 7259, 7, 10, 25802, 6, 897, 6, 10147, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Tokenized Labels IDs: [86, 8, 215, 204, 11434, 6, 4030, 141, 263, 1516, 5765, 9361, 16, 628, 9740, 11, 1413, 7, 6714, 291, 1111, 5, 37, 907, 4030, 3141, 41, 5078, 517, 61, 141, 2127, 27200, 30, 11856, 6, 24308, 31, 7, 8114, 5578, 6, 11, 24037, 31, 7, 8114, 13622, 5, 37, 14500, 7, 16, 748, 11, 2056, 141, 2237, 12, 8, 3409, 13, 8, 638, 7, 3113, 391, 99, 17, 19746, 2661, 7038, 41, 254, 13223, 201, 3, 9, 789, 18, 18532, 1470, 3, 17, 23552, 28, 6990, 8, 7752, 6266, 13, 628, 11, 17452, 126, 296, 7, 11, 1438, 5, 707, 5, 736, 13240, 10498, 6, 3, 9, 6077, 38, 17, 29006, 7, 447, 343, 6, 47, 8, 991, 17901, 44, 205, 13223, 31, 7, 13767, 30, 17687, 5, 451, 141, 3, 12895, 160, 1297, 280, 12, 1705, 8, 29063, 13, 8, 8084, 11, 141, 582, 3, 9, 11200, 16, 160, 1057, 5, 451, 47, 4187, 12, 19019, 8, 13951, 13, 8, 28332, 3, 22722, 7, 6, 3, 9, 939, 13, 15124, 11, 13045, 73, 19386, 827, 23236, 725, 24, 141, 708, 16069, 1019, 8, 24856, 5, 707, 5, 10498, 17583, 3, 9, 2399, 372, 13, 2273, 21, 160, 416, 2253, 6, 379, 160, 7731, 511, 18, 77, 18, 13695, 6, 12202, 1079, 96, 683, 4365, 121, 27815, 6, 3, 9, 3, 18720, 30059, 11, 11774, 13, 2724, 205, 13223, 21807, 7, 117, 707, 5, 11566, 120, 29, 96, 427, 162, 121, 19553, 6, 3, 9, 7799, 14761, 152, 343, 11, 2647, 9290, 117, 11, 707, 5, 13962, 96, 7754, 121, 30486, 6, 3, 9, 18592, 9739, 11, 21244, 5, 10965, 6, 79, 133, 17046, 30, 3, 9, 2027, 12, 2075, 8, 28332, 3, 22722, 1069, 16, 8, 411, 16310, 5412, 13, 8, 18389, 63, 5994, 5, 2940, 628, 6696, 6, 8, 3, 4256, 9506, 7, 23, 127, 6, 47, 5005, 28, 8, 1251, 748, 6, 379, 3, 9, 538, 18, 858, 18, 532, 18, 1408, 3, 3903, 9, 1765, 1407, 24, 133, 995, 135, 12, 2367, 3550, 17, 7633, 38, 79, 6086, 26, 7231, 139, 73, 4059, 1054, 9964, 5, 282, 8, 9506, 7, 23, 127, 646, 8, 1455, 13, 17687, 31, 7, 15607, 6, 8, 4627, 47, 3353, 28, 23550, 11, 10147, 5, 5258, 410, 79, 214, 24, 70, 2027, 133, 991, 135, 12, 8, 3023, 13, 8, 801, 8084, 11, 1909, 5, 282, 79, 15319, 8, 28332, 3, 22722, 6, 8, 9506, 7, 23, 127, 47, 8247, 3, 35, 6106, 19565, 57, 3, 9, 2021, 827, 6772, 24, 3, 7, 20978, 8, 4383, 12, 165, 2583, 5, 37, 4627, 4393, 26, 12, 1961, 610, 6, 68, 8, 3, 22722, 31, 7, 827, 1553, 12, 18960, 28, 70, 1002, 5, 1142, 38, 8, 9506, 7, 23, 127, 47, 30, 8, 548, 397, 13, 271, 12, 52, 29, 3943, 6, 707, 5, 30486, 3030, 12, 8195, 8, 4383, 31, 7, 3583, 3, 3903, 9, 1765, 1407, 5, 37, 3, 22722, 31, 7, 827, 13468, 26, 300, 8, 9506, 7, 23, 127, 6, 68, 8, 4383, 3, 7361, 5697, 6, 5046, 1]\n",
            "\n",
            "Sample 2:\n",
            "Tokenized Input IDs: [5945, 60, 10, 19202, 20087, 7, 10, 8, 18136, 26695, 31, 7, 6, 10632, 29, 6, 1289, 26, 2057, 9, 6, 78, 52, 2110, 49, 6, 411, 195, 11687, 9, 6, 1997, 6, 160, 32, 3, 17057, 7, 10, 180, 6051, 6, 9062, 6, 11930, 6, 16600, 10450, 7, 10, 8, 180, 6051, 13, 1289, 26, 2057, 9, 6, 37, 180, 6051, 13, 1289, 26, 2057, 9, 6, 4716, 6, 8, 18136, 26695, 31, 7, 6, 5827, 6, 8, 18136, 26695, 6, 9634, 6, 12268, 749, 17585, 7, 10, 4472, 52, 262, 7259, 7, 10, 11444, 6, 10147, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Tokenized Labels IDs: [86, 3, 9, 1322, 623, 550, 6, 213, 8, 1997, 6660, 782, 2756, 49, 11, 8, 5956, 47, 1442, 49, 6, 132, 16415, 3, 9, 9393, 5827, 801, 38, 1289, 26, 2057, 9, 5, 100, 3, 35, 8694, 1054, 5827, 47, 234, 12, 14231, 13, 66, 8803, 11, 4342, 6, 284, 28, 70, 293, 775, 8075, 11, 21369, 5, 37, 5827, 47, 3, 9, 286, 13, 2790, 11, 3337, 6, 28, 165, 8328, 2602, 11, 3, 31225, 9437, 5, 37, 733, 4396, 28, 3, 9, 1021, 4940, 2650, 10632, 29, 6, 113, 141, 131, 2120, 13369, 5, 10632, 29, 4114, 28, 112, 18573, 16, 3, 9, 422, 12268, 1084, 8, 3023, 13, 1289, 26, 2057, 9, 5, 978, 1362, 141, 4049, 11904, 365, 15124, 4616, 116, 3, 88, 47, 3, 9, 1871, 6, 11, 112, 18573, 47, 66, 3, 88, 141, 646, 16, 8, 296, 5, 10632, 29, 31, 7, 18573, 47, 3, 9, 7624, 11, 9839, 388, 6, 3, 9, 1798, 4472, 52, 113, 141, 728, 15883, 8, 4963, 7, 13, 1289, 26, 2057, 9, 5, 216, 141, 2804, 323, 186, 5221, 7, 13, 8, 5827, 12, 10632, 29, 6, 14, 53, 112, 819, 28, 1937, 13, 13414, 17736, 11, 2971, 5529, 21168, 7, 5, 10632, 29, 31, 7, 1305, 13, 175, 5221, 7, 47, 81, 8, 13660, 180, 6051, 13, 1289, 26, 2057, 9, 6, 3, 9, 10931, 13, 73, 6487, 179, 579, 24, 228, 5334, 165, 587, 40, 588, 8, 1418, 12, 610, 8, 182, 2479, 13, 1405, 5, 555, 239, 6, 298, 6990, 8, 5827, 28, 112, 18573, 6, 10632, 29, 3, 25220, 1286, 3, 9, 5697, 9634, 5, 9014, 8, 9634, 6, 3, 88, 3883, 46, 4913, 11930, 24, 5468, 13, 8, 180, 6051, 13, 1289, 26, 2057, 9, 11, 165, 213, 7932, 7, 5, 37, 11930, 5111, 24, 8, 16600, 47, 5697, 1659, 441, 8, 5827, 6, 4879, 15, 26, 57, 3, 9, 2971, 5529, 19744, 718, 8, 18136, 26695, 5, 10632, 29, 31, 7, 842, 3, 7, 2091, 15, 26, 28, 10147, 11, 11444, 38, 3, 88, 608, 8, 11930, 5, 216, 2124, 24, 3, 88, 398, 253, 8, 180, 6051, 13, 1289, 26, 2057, 9, 11, 169, 165, 579, 12, 1822, 1289, 26, 2057, 9, 45, 8, 8293, 3859, 24, 16026, 12, 10123, 34, 5, 978, 18573, 6, 2492, 8, 11444, 16, 112, 2053, 6, 4686, 12, 199, 376, 30, 112, 13118, 5, 275, 78, 6, 8, 2027, 1553, 5, 10632, 29, 11, 112, 18573, 5187, 15, 26, 190, 8, 23968, 88, 8283, 7572, 13, 1289, 26, 2057, 9, 6, 5008, 186, 2428, 590, 8, 194, 5, 328, 15110, 3, 9, 1196, 13, 14231, 6, 128, 2609, 11, 128, 59, 78, 2609, 5, 555, 239, 6, 298, 12529, 3, 9, 3, 5206, 15, 17, 63, 4716, 147, 3, 9, 1659, 20217, 29, 15, 6, 79, 15110, 3, 9, 563, 13, 281, 21746, 7, 5, 37, 281, 21746, 7, 6, 113, 141, 118, 12, 52, 297, 53, 8, 5827, 31, 7, 21155, 6, 4399, 26, 24, 10632, 29, 11, 112, 18573, 609, 147, 70, 1]\n",
            "\n",
            "Sample 3:\n",
            "Tokenized Input IDs: [5945, 60, 10, 27951, 20087, 7, 10, 23959, 6, 3576, 6, 1079, 9, 6736, 6, 14883, 4339, 53, 18136, 7, 6, 160, 32, 3, 17057, 7, 10, 597, 5661, 10450, 7, 10, 10645, 6, 1511, 6, 11625, 6, 690, 6, 2812, 749, 17585, 7, 10, 597, 5661, 262, 7259, 7, 10, 8700, 6, 333, 6, 897, 6, 11444, 6, 17142, 6, 20595, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Tokenized Labels IDs: [1447, 1286, 3, 9, 97, 6, 16, 3, 9, 422, 6, 14249, 1511, 718, 14883, 4339, 53, 18136, 7, 6, 280, 3776, 12, 888, 44, 3, 9, 9257, 4974, 5, 37, 1511, 47, 9190, 1361, 16, 3, 9, 20675, 10645, 6, 3, 8623, 57, 7293, 53, 8022, 30, 66, 4458, 5, 37, 11228, 89, 32, 40, 157, 130, 3, 9, 885, 18, 157, 29, 155, 573, 6, 840, 29938, 120, 6, 8120, 544, 57, 70, 2471, 333, 21, 70, 234, 11, 284, 119, 5, 421, 160, 32, 6, 1079, 9, 6736, 6, 47, 3, 9, 1021, 23959, 113, 141, 1310, 2301, 12, 14883, 4339, 53, 18136, 7, 6, 6055, 12, 6754, 8, 16856, 13, 8, 690, 11, 253, 128, 78, 11706, 16, 8, 4447, 6, 27602, 75, 1511, 5, 216, 47, 3, 9, 5065, 6, 3, 1618, 3781, 388, 16, 112, 1480, 3, 17, 16103, 725, 6, 28, 2164, 1268, 11, 3, 8343, 75, 53, 1692, 2053, 5, 1079, 9, 6736, 47, 168, 18, 60, 7576, 1054, 859, 8, 11228, 16588, 6, 113, 3, 29099, 112, 73, 12301, 1007, 12365, 12, 4831, 11, 112, 73, 75, 15159, 1418, 12, 4602, 237, 8, 167, 975, 19732, 53, 29063, 5, 282, 1079, 9, 6736, 10166, 139, 112, 126, 280, 6, 3, 88, 1224, 1632, 2718, 13, 3, 9, 939, 13, 6765, 3, 16526, 7, 24, 141, 118, 9564, 1744, 53, 8, 1511, 21, 203, 5, 37, 11228, 89, 32, 40, 157, 23874, 15, 26, 81, 175, 984, 16, 3, 11823, 88, 26, 12, 1496, 6, 70, 13256, 11289, 756, 3, 9, 23874, 6, 38, 3, 99, 8, 182, 8552, 7, 300, 135, 1213, 3, 9, 3731, 5805, 2829, 5, 555, 239, 6, 298, 13593, 53, 190, 8, 1511, 2812, 6, 1079, 9, 6736, 147, 88, 986, 192, 12766, 10989, 12104, 3, 9, 15124, 2320, 79, 141, 894, 1480, 44, 706, 5, 37, 2320, 6, 79, 243, 6, 3776, 12, 4049, 1273, 139, 5551, 799, 5, 9874, 15795, 26, 57, 8, 5221, 6, 1079, 9, 6736, 1500, 12, 9127, 48, 3, 15, 7315, 4992, 1848, 5, 282, 706, 4728, 6, 1079, 9, 6736, 6086, 26, 139, 8, 2164, 222, 13518, 13, 8, 1511, 6, 2627, 3, 9, 4816, 1580, 91, 21, 136, 3957, 13, 8, 3, 29748, 2320, 5, 10768, 7, 2804, 6, 11, 8, 706, 3776, 12, 1604, 72, 3, 32, 1109, 1162, 28, 284, 5792, 1962, 5, 37, 2943, 149, 1361, 190, 8, 5658, 6162, 6, 11, 8, 8552, 7, 3776, 12, 240, 30, 3, 9, 280, 13, 70, 293, 6, 17463, 53, 590, 8, 4205, 11, 1501, 114, 3, 9, 7863, 17472, 10518, 5, 1142, 38, 1079, 9, 6736, 47, 81, 12, 428, 95, 30, 112, 13118, 6, 3, 88, 3, 16972, 3, 9, 2320, 4125, 44, 8, 3023, 13, 8, 1511, 2812, 5, 37, 2320, 47, 13205, 66, 16, 1001, 6, 28, 3, 9, 3, 4500, 24, 27972, 70, 522, 5, 282, 1079, 9, 6736, 15319, 6, 8, 2320, 1553, 12, 1482, 550, 6, 70, 29728, 11289, 185, 26, 2317, 38, 79, 19803, 139, 8, 706, 5, 30197, 26, 12, 1]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Visualize a few samples of the tokenized data\n",
        "for i in range(3):  # Change the range to see more or fewer samples\n",
        "    print(f\"Sample {i+1}:\")\n",
        "    print(\"Tokenized Input IDs:\", tokenized_dataset[i]['input_ids'])\n",
        "    print(\"Tokenized Labels IDs:\", tokenized_dataset[i]['labels'])\n",
        "    print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_xMNjslOlnl"
      },
      "source": [
        "## 5. Fine tuning the model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall transformers torch datasets accelerate -y\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "axq6uIlruQvj",
        "outputId": "9a19f435-5c3b-46fa-fb33-dc9f8d10ef0f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: transformers 4.42.4\n",
            "Uninstalling transformers-4.42.4:\n",
            "  Successfully uninstalled transformers-4.42.4\n",
            "Found existing installation: torch 2.3.1+cu121\n",
            "Uninstalling torch-2.3.1+cu121:\n",
            "  Successfully uninstalled torch-2.3.1+cu121\n",
            "Found existing installation: datasets 2.20.0\n",
            "Uninstalling datasets-2.20.0:\n",
            "  Successfully uninstalled datasets-2.20.0\n",
            "\u001b[33mWARNING: Skipping accelerate as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.27.4 torch datasets accelerate -U\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "XdHaeWFUu6YG",
        "outputId": "9c906c37-3868-43b3-fe01-d10bdf3ff781"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.27.4\n",
            "  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch\n",
            "  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Using cached datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.32.1-py3-none-any.whl (314 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.1/314.1 kB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.4) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.4) (0.23.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.4) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.4) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.4) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.4) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.4) (2.32.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.27.4)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m106.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.4) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.27.4) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.27.4) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.27.4) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.27.4) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: tokenizers, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, transformers, nvidia-cusolver-cu12, torch, datasets, accelerate\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "Successfully installed accelerate-0.32.1 datasets-2.20.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 tokenizers-0.13.3 torch-2.3.1 transformers-4.27.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "datasets",
                  "tokenizers",
                  "torch",
                  "torchgen",
                  "transformers"
                ]
              },
              "id": "1231bac591c748c7ad8c7e798540ad20"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377,
          "referenced_widgets": [
            "982b00316d45420e911a5dd008265f0a",
            "a7f84560c5d04c49a89dc27a102fb403",
            "e612fd383abe42278ebc5f0165a55c7f",
            "baafbfce9a2842e59d1449950fe4a821",
            "f3c00d1b7dbf4e70b12241f135796e3f",
            "b7ab7c7a18b54b809465b912db44cbfd",
            "8d596507d3ad40848f683d0995ddf7bd",
            "2e1c134554b54aaea03c89b0cd76ed68",
            "4e51678ce8ba4904807a44a36f7d87fc",
            "e060b597ed794d1b9ce44289f26cf0ec",
            "63412c263e5746148021647962da8ee6"
          ]
        },
        "id": "tLAtMbC-Or4p",
        "outputId": "aca1bf0c-6a1d-4963-8248-ce314286b22d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "982b00316d45420e911a5dd008265f0a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [375/375 17:54, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=375, training_loss=0.0, metrics={'train_runtime': 1078.0135, 'train_samples_per_second': 2.783, 'train_steps_per_second': 0.348, 'total_flos': 2.5656947638272e+16, 'train_loss': 0.0, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, Trainer, TrainingArguments\n",
        "\n",
        "# Load the pre-trained model\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained('google/flan-t5-xl')\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results/flan-t5-xl',\n",
        "    evaluation_strategy='epoch',\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=1,  # Reduce batch size\n",
        "    per_device_eval_batch_size=1,   # Reduce batch size\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    save_steps=10_000,\n",
        "    logging_dir='./logs',\n",
        "    gradient_accumulation_steps=8,  # Increase gradient accumulation steps\n",
        "    fp16=True,  # Enable mixed precision training\n",
        ")\n",
        "\n",
        "# Create a Trainer instance\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    eval_dataset=tokenized_dataset,  # You might want to create a separate validation dataset\n",
        ")\n",
        "\n",
        "# Fine-tune the model\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to clean up the memory\n",
        "\n",
        "import os\n",
        "os._exit(00)  # This will restart the runtime\n"
      ],
      "metadata": {
        "id": "pgO4vXVW0m5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "IZ4TYIjAvzAT"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHikonR4YcXQ",
        "outputId": "4a1c913d-ed20-47f2-9cc3-5f92609c92f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/sample_data/fine-tuned-t5-xl/tokenizer_config.json',\n",
              " '/content/sample_data/fine-tuned-t5-xl/special_tokens_map.json',\n",
              " '/content/sample_data/fine-tuned-t5-xl/spiece.model',\n",
              " '/content/sample_data/fine-tuned-t5-xl/added_tokens.json',\n",
              " '/content/sample_data/fine-tuned-t5-xl/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "model.save_pretrained('/content/sample_data/fine-tuned-t5-xl')\n",
        "tokenizer.save_pretrained('/content/sample_data/fine-tuned-t5-xl')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "shutil.make_archive('/content/sample_data/fine-tuned-t5-xl', 'zip', '/content/sample_data/fine-tuned-t5-xl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RnR1mBTJ7FKA",
        "outputId": "7eff2a62-be33-4130-ef73-09fec5f09ae5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/sample_data/fine-tuned-t5-xl.zip'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-o7mr8ts767l",
        "outputId": "67436292-9dd5-4c2e-c000-bb0e1b28be55"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy the compressed file to Google Drive\n",
        "shutil.copy('/content/sample_data/fine-tuned-t5.zip', '/content/drive/MyDrive/fine-tuned-t5.zip')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "myGs8rCw8GT4",
        "outputId": "8b7c9b9e-fea7-4ac2-d5c1-6c1e01849b61"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/fine-tuned-t5.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuH2dUlTYa2a"
      },
      "source": [
        "## 6. Generate Stories with the Fine-Tuned Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "75628a074aab4c2e8ace1c849823184c",
            "8754ba1170f74d8ca2d67389f9f16d2b",
            "dc88ab71e2ac4608bfbf1e63b8755188",
            "611425ca5942465f82ab1997158e535c",
            "78ebdb0130d14b1285c930fc37213b71",
            "c570e54e5cdc4b9d822669eeb5f772d9",
            "748142249d38408bab1aa1155c09280e",
            "865d195da64b4a08b5a55aa01f14a6ff",
            "770bc8e6436340e6be5e66c344449c91",
            "c3ce21a8b23e4f76af6a7cecd12c7a9c",
            "cf264cca80d04ed392afd7ad8adfef0a"
          ]
        },
        "id": "zg4sC_HjP8Gu",
        "outputId": "1b60b3d5-7f03-497e-cd11-7d9dcbc9c418"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "75628a074aab4c2e8ace1c849823184c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dog wanted to be outside and had a good day on the beach. So he went out in the sun with a beach toy, and spent all day on the sand.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
        "\n",
        "# Load the fine-tuned model and tokenizer\n",
        "model_path = '/content/sample_data/fine-tuned-t5-xl'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
        "\n",
        "# Create a pipeline for text generation\n",
        "text2text_generator = pipeline('text2text-generation', model=model, tokenizer=tokenizer)\n",
        "\n",
        "# Define the prompt\n",
        "keywords = [\"dog\", \"sun\", \"beach\"]\n",
        "emotion = \"happy\"\n",
        "userpref = \"history\"\n",
        "\n",
        "prompt = (\n",
        "    f\"Generate a story that evokes a {emotion} emotion. The story should feature a \"\n",
        "    f\"{keywords[0]}, a {keywords[1]}, and a {keywords[2]}. \"\n",
        "    f\"Additionally, incorporate elements of {userpref} to enhance the narrative. \"\n",
        "    f\"Ensure the {userpref} aspects are seamlessly integrated and contribute to the overall {emotion} tone of the story.\"\n",
        ")\n",
        "\n",
        "# Generate the story\n",
        "generated_story = text2text_generator(prompt, max_length=512, do_sample=True, top_p=0.95, num_return_sequences=1)\n",
        "\n",
        "# Print the generated story\n",
        "print(generated_story[0]['generated_text'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa3pLH98a-He",
        "outputId": "0bc961fd-79be-4557-9f41-411d8f7e010d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated story saved to /content/sample_data/generated_story_flan_t5_XL_finetuned.txt\n"
          ]
        }
      ],
      "source": [
        "# Extract the generated text\n",
        "story_text = generated_story[0]['generated_text']\n",
        "\n",
        "# Save the generated story to a text file\n",
        "output_file_path = '/content/sample_data/generated_story_flan_t5_XL_finetuned.txt'\n",
        "with open(output_file_path, 'w') as file:\n",
        "    file.write(story_text)\n",
        "\n",
        "print(f\"Generated story saved to {output_file_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DVB9yYpeT_c"
      },
      "source": [
        "## 7. Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTI8DgyCeh0z"
      },
      "source": [
        "### 7.1 Qualitative Evaluation\n",
        "\n",
        "#### **Human Evaluation**\n",
        "\n",
        "- Content Relevance: The story should feature a dog, the sun, and the beach.\n",
        "\n",
        "  - Check: The story prominently features a dog, mentions the sun, and describes the beach.\n",
        "\n",
        "- Emotion Elicitation: The story should evoke a happy emotion.\n",
        "\n",
        "  - Check: The story conveys a sense of happiness through the dog's enjoyment of the day on the beach.\n",
        "\n",
        "- Incorporation of User Preference (History): The story should include historical elements seamlessly.\n",
        "\n",
        "  - Check: The story does not include any historical elements.\n",
        "\n",
        "- Coherence and Fluency: The story should be coherent and fluent.\n",
        "\n",
        "  - Check: The story is coherent and fluent with no issues affecting readability.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cj3lgXClfWTd"
      },
      "source": [
        "### 7.2 Quantitative Evaluation\n",
        "\n",
        "####  **BLEU and ROUGE Scores**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cg2CpPsdeUbU",
        "outputId": "bc2cb016-7ba2-403d-91cb-01b4984d8fb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU Score Before Fine-Tuning: 0.0\n",
            "BLEU Score After Fine-Tuning: 0.0\n",
            "ROUGE Scores Before Fine-Tuning: {'rouge1': AggregateScore(low=Score(precision=0.7741935483870968, recall=0.08304498269896193, fmeasure=0.15), mid=Score(precision=0.7741935483870968, recall=0.08304498269896193, fmeasure=0.15), high=Score(precision=0.7741935483870968, recall=0.08304498269896193, fmeasure=0.15)), 'rouge2': AggregateScore(low=Score(precision=0.16666666666666666, recall=0.017361111111111112, fmeasure=0.031446540880503145), mid=Score(precision=0.16666666666666666, recall=0.017361111111111112, fmeasure=0.031446540880503145), high=Score(precision=0.16666666666666666, recall=0.017361111111111112, fmeasure=0.031446540880503145)), 'rougeL': AggregateScore(low=Score(precision=0.5161290322580645, recall=0.05536332179930796, fmeasure=0.1), mid=Score(precision=0.5161290322580645, recall=0.05536332179930796, fmeasure=0.1), high=Score(precision=0.5161290322580645, recall=0.05536332179930796, fmeasure=0.1)), 'rougeLsum': AggregateScore(low=Score(precision=0.6129032258064516, recall=0.0657439446366782, fmeasure=0.11874999999999998), mid=Score(precision=0.6129032258064516, recall=0.0657439446366782, fmeasure=0.11874999999999998), high=Score(precision=0.6129032258064516, recall=0.0657439446366782, fmeasure=0.11874999999999998))}\n",
            "ROUGE Scores After Fine-Tuning: {'rouge1': AggregateScore(low=Score(precision=0.75, recall=0.08304498269896193, fmeasure=0.14953271028037385), mid=Score(precision=0.75, recall=0.08304498269896193, fmeasure=0.14953271028037385), high=Score(precision=0.75, recall=0.08304498269896193, fmeasure=0.14953271028037385)), 'rouge2': AggregateScore(low=Score(precision=0.12903225806451613, recall=0.013888888888888888, fmeasure=0.02507836990595611), mid=Score(precision=0.12903225806451613, recall=0.013888888888888888, fmeasure=0.02507836990595611), high=Score(precision=0.12903225806451613, recall=0.013888888888888888, fmeasure=0.02507836990595611)), 'rougeL': AggregateScore(low=Score(precision=0.53125, recall=0.058823529411764705, fmeasure=0.1059190031152648), mid=Score(precision=0.53125, recall=0.058823529411764705, fmeasure=0.1059190031152648), high=Score(precision=0.53125, recall=0.058823529411764705, fmeasure=0.1059190031152648)), 'rougeLsum': AggregateScore(low=Score(precision=0.53125, recall=0.058823529411764705, fmeasure=0.1059190031152648), mid=Score(precision=0.53125, recall=0.058823529411764705, fmeasure=0.1059190031152648), high=Score(precision=0.53125, recall=0.058823529411764705, fmeasure=0.1059190031152648))}\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_metric\n",
        "\n",
        "# Load the BLEU and ROUGE metrics\n",
        "bleu = load_metric('bleu')\n",
        "rouge = load_metric('rouge')\n",
        "\n",
        "# Load the generated stories from the files\n",
        "with open('/content/sample_data/generated_story_flan-t5-xl.txt', 'r', encoding='utf-8') as file:\n",
        "    story_before_fine_tuning = file.read()\n",
        "\n",
        "with open('/content/sample_data/generated_story_flan_t5_XL_finetuned.txt', 'r', encoding='utf-8') as file:\n",
        "    story_after_fine_tuning = file.read()\n",
        "\n",
        "# Load the reference story from the file\n",
        "with open('/content/sample_data/reference_story.txt', 'r', encoding='utf-8') as file:\n",
        "    reference_story = file.read()\n",
        "\n",
        "# Tokenize the generated and reference stories\n",
        "generated_tokens_before = [story_before_fine_tuning.split()]\n",
        "generated_tokens_after = [story_after_fine_tuning.split()]\n",
        "reference_tokens = [[reference_story.split()]]  # Reference story tokenized\n",
        "\n",
        "# Compute BLEU scores\n",
        "bleu_result_before = bleu.compute(predictions=generated_tokens_before, references=reference_tokens)\n",
        "bleu_result_after = bleu.compute(predictions=generated_tokens_after, references=reference_tokens)\n",
        "\n",
        "print(\"BLEU Score Before Fine-Tuning:\", bleu_result_before['bleu'])\n",
        "print(\"BLEU Score After Fine-Tuning:\", bleu_result_after['bleu'])\n",
        "\n",
        "# Compute ROUGE scores\n",
        "rouge_result_before = rouge.compute(predictions=[story_before_fine_tuning], references=[reference_story])\n",
        "rouge_result_after = rouge.compute(predictions=[story_after_fine_tuning], references=[reference_story])\n",
        "\n",
        "print(\"ROUGE Scores Before Fine-Tuning:\", rouge_result_before)\n",
        "print(\"ROUGE Scores After Fine-Tuning:\", rouge_result_after)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge-score\n",
        "!pip install datasets\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Te2dJhUK-IdT",
        "outputId": "522e0b49-52b3-4f17-c4b2-c739910663a8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.25.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (4.66.4)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=01afa78ffb97da23857282f299af0a023927da3f055651e70df35b0fd7af8fa0\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.1.2\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NE97EBQcj7WC"
      },
      "source": [
        "#### **Perplexity**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tQMb6CZj_o0",
        "outputId": "f96c1d15-951f-4a3c-9810-a79f3077fbe3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perplexity Before Fine-Tuning: 1.931144118309021\n",
            "Perplexity After Fine-Tuning: 1.298383116722107\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "# Load the tokenizer and model\n",
        "model_path = '/content/sample_data/fine-tuned-t5'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
        "\n",
        "# Load the generated stories from the files\n",
        "with open('/content/sample_data/generated_story_flan-t5-xl.txt', 'r', encoding='utf-8') as file:\n",
        "    story_before_fine_tuning = file.read()\n",
        "\n",
        "with open('/content/sample_data/generated_story_flan_t5_XL_finetuned.txt', 'r', encoding='utf-8') as file:\n",
        "    story_after_fine_tuning = file.read()\n",
        "\n",
        "# Tokenize the input texts\n",
        "inputs_before = tokenizer(story_before_fine_tuning, return_tensors='pt')\n",
        "inputs_after = tokenizer(story_after_fine_tuning, return_tensors='pt')\n",
        "\n",
        "# Move tensors to GPU if available\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)\n",
        "inputs_before = {key: value.to(device) for key, value in inputs_before.items()}\n",
        "inputs_after = {key: value.to(device) for key, value in inputs_after.items()}\n",
        "\n",
        "# Compute loss for before fine-tuning\n",
        "with torch.no_grad():\n",
        "    outputs_before = model(**inputs_before, labels=inputs_before[\"input_ids\"])\n",
        "    loss_before = outputs_before.loss\n",
        "    perplexity_before = torch.exp(loss_before)\n",
        "\n",
        "# Compute loss for after fine-tuning\n",
        "with torch.no_grad():\n",
        "    outputs_after = model(**inputs_after, labels=inputs_after[\"input_ids\"])\n",
        "    loss_after = outputs_after.loss\n",
        "    perplexity_after = torch.exp(loss_after)\n",
        "\n",
        "print(\"Perplexity Before Fine-Tuning:\", perplexity_before.item())\n",
        "print(\"Perplexity After Fine-Tuning:\", perplexity_after.item())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O84p9ntakZD4"
      },
      "source": [
        "- The decrease in perplexity after fine-tuning demonstrates an improvement in the model's ability to generate text that is similar to the training data.\n",
        "\n",
        "- A lower perplexity value after fine-tuning indicates that the model has become more adept at capturing the patterns and structures in the text, leading to more accurate predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehoHxTKtkehQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "929cd860966648938068f2160d3f72c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a08db49d8cb24d3e9310489f31e1f6b8",
              "IPY_MODEL_2633ad03604f4d60866dbf87051df4d1",
              "IPY_MODEL_51b5979f5a2b4e8fa54919a0e5ae4612"
            ],
            "layout": "IPY_MODEL_74127e2a462d452e90a25c732625bb90"
          }
        },
        "a08db49d8cb24d3e9310489f31e1f6b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c051106b580b4256b3742af4c1ea1d91",
            "placeholder": "​",
            "style": "IPY_MODEL_8047ae216fcb48d99c63bd881a1be0d2",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "2633ad03604f4d60866dbf87051df4d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8357a3028e8c4eb0bf01c80c0bfc5af5",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_943fe98675df4fb88eada309c84412d4",
            "value": 2
          }
        },
        "51b5979f5a2b4e8fa54919a0e5ae4612": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67874516341b4dbd81f47e05d186f155",
            "placeholder": "​",
            "style": "IPY_MODEL_1a2de30bba69483ba999511f2820ce46",
            "value": " 2/2 [00:01&lt;00:00,  1.28it/s]"
          }
        },
        "74127e2a462d452e90a25c732625bb90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c051106b580b4256b3742af4c1ea1d91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8047ae216fcb48d99c63bd881a1be0d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8357a3028e8c4eb0bf01c80c0bfc5af5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "943fe98675df4fb88eada309c84412d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "67874516341b4dbd81f47e05d186f155": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a2de30bba69483ba999511f2820ce46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d081a51209344b9a7f3ebe4ffca9d0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d7c72edf420c49f0b3375ca4fb3fe44e",
              "IPY_MODEL_1f07205c1329480387f7c3bd61ff1d2e",
              "IPY_MODEL_336c52413ef144248e5d9514396da7ef"
            ],
            "layout": "IPY_MODEL_e188e9b534774129a37ae9b2c7dab2aa"
          }
        },
        "d7c72edf420c49f0b3375ca4fb3fe44e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74066a827a5c459fab44d60f533c7074",
            "placeholder": "​",
            "style": "IPY_MODEL_da3bc0325df84defbc0526ab7c1b47ea",
            "value": "Map: 100%"
          }
        },
        "1f07205c1329480387f7c3bd61ff1d2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bcb0f9fc3c5406fbccb28ee2522e4d1",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_00c3de6ec2844b37be660b32eac0dfb5",
            "value": 1000
          }
        },
        "336c52413ef144248e5d9514396da7ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_309664e894be4bcf8fa75381b657d369",
            "placeholder": "​",
            "style": "IPY_MODEL_d29beda83e86417cb71d94ab71845565",
            "value": " 1000/1000 [00:01&lt;00:00, 845.30 examples/s]"
          }
        },
        "e188e9b534774129a37ae9b2c7dab2aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74066a827a5c459fab44d60f533c7074": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da3bc0325df84defbc0526ab7c1b47ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5bcb0f9fc3c5406fbccb28ee2522e4d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00c3de6ec2844b37be660b32eac0dfb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "309664e894be4bcf8fa75381b657d369": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d29beda83e86417cb71d94ab71845565": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "982b00316d45420e911a5dd008265f0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a7f84560c5d04c49a89dc27a102fb403",
              "IPY_MODEL_e612fd383abe42278ebc5f0165a55c7f",
              "IPY_MODEL_baafbfce9a2842e59d1449950fe4a821"
            ],
            "layout": "IPY_MODEL_f3c00d1b7dbf4e70b12241f135796e3f"
          }
        },
        "a7f84560c5d04c49a89dc27a102fb403": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7ab7c7a18b54b809465b912db44cbfd",
            "placeholder": "​",
            "style": "IPY_MODEL_8d596507d3ad40848f683d0995ddf7bd",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "e612fd383abe42278ebc5f0165a55c7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e1c134554b54aaea03c89b0cd76ed68",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4e51678ce8ba4904807a44a36f7d87fc",
            "value": 2
          }
        },
        "baafbfce9a2842e59d1449950fe4a821": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e060b597ed794d1b9ce44289f26cf0ec",
            "placeholder": "​",
            "style": "IPY_MODEL_63412c263e5746148021647962da8ee6",
            "value": " 2/2 [00:01&lt;00:00,  1.24it/s]"
          }
        },
        "f3c00d1b7dbf4e70b12241f135796e3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7ab7c7a18b54b809465b912db44cbfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d596507d3ad40848f683d0995ddf7bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e1c134554b54aaea03c89b0cd76ed68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e51678ce8ba4904807a44a36f7d87fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e060b597ed794d1b9ce44289f26cf0ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63412c263e5746148021647962da8ee6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75628a074aab4c2e8ace1c849823184c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8754ba1170f74d8ca2d67389f9f16d2b",
              "IPY_MODEL_dc88ab71e2ac4608bfbf1e63b8755188",
              "IPY_MODEL_611425ca5942465f82ab1997158e535c"
            ],
            "layout": "IPY_MODEL_78ebdb0130d14b1285c930fc37213b71"
          }
        },
        "8754ba1170f74d8ca2d67389f9f16d2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c570e54e5cdc4b9d822669eeb5f772d9",
            "placeholder": "​",
            "style": "IPY_MODEL_748142249d38408bab1aa1155c09280e",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "dc88ab71e2ac4608bfbf1e63b8755188": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_865d195da64b4a08b5a55aa01f14a6ff",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_770bc8e6436340e6be5e66c344449c91",
            "value": 2
          }
        },
        "611425ca5942465f82ab1997158e535c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3ce21a8b23e4f76af6a7cecd12c7a9c",
            "placeholder": "​",
            "style": "IPY_MODEL_cf264cca80d04ed392afd7ad8adfef0a",
            "value": " 2/2 [00:08&lt;00:00,  3.51s/it]"
          }
        },
        "78ebdb0130d14b1285c930fc37213b71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c570e54e5cdc4b9d822669eeb5f772d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "748142249d38408bab1aa1155c09280e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "865d195da64b4a08b5a55aa01f14a6ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "770bc8e6436340e6be5e66c344449c91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c3ce21a8b23e4f76af6a7cecd12c7a9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf264cca80d04ed392afd7ad8adfef0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}